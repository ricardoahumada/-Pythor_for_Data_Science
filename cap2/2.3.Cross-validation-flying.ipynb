{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0337c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/2008_small.zip',index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ArrDelay'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6742741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['ArrDelay'].notnull()]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ef0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(labels=['ArrDelay'], axis=1)\n",
    "target = df['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae58598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef795bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_data=data[data.columns[data.isna().any()]]\n",
    "\n",
    "nan_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d834871",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(labels=(nan_data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af809d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e53334",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.describe(), target.isna().sum(), target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(data)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "# Eliminamos DepDelay para comprobar su impacto\n",
    "# del numerical_columns[ numerical_columns.index('DepDelay')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b370b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el transformador y asociamos cada uno de estos preprocesadores con sus respectivas columnas.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83066041",
   "metadata": {},
   "source": [
    "# Training error vs testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62541a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(preprocessor, LinearRegression())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos nuestro conjunto de datos.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c88ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos nuestro modelo.\n",
    "\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# el error de entrenamiento.\n",
    "\n",
    "target_predicted = model.predict(data_train)\n",
    "score = mean_absolute_error(target_train, target_predicted)\n",
    "r2 = r2_score(target_train, target_predicted)\n",
    "print(f\"Los errores de entrenamiento son {score:.6f} y {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81100a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.values-target_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# el error de prueba.\n",
    "\n",
    "target_predicted = model.predict(data_test)\n",
    "score = mean_absolute_error(target_test, target_predicted)\n",
    "r2 = r2_score(target_test, target_predicted)\n",
    "print(f\"Los errores de prueba son {score:.6f} y {r2:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6178385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(target)), target, color='blue')\n",
    "plt.scatter(range(len(target_predicted)), target_predicted, color='red')\n",
    "plt.title('Target vs predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e826d537",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "cv_results = cross_validate(\n",
    "    model, data, target, cv=cv, scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revertimos los negativos\n",
    "cv_results[\"test_error\"] = -cv_results[\"test_score\"]\n",
    "\n",
    "# verificamos los resultados\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa32783",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos 40 entradas en nuestro marco de datos resultante porque realizamos 40 divisiones.\n",
    "# Por lo tanto, podemos mostrar la distribución del error de prueba y así tener una estimación de su variabilidad.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv_results[\"test_error\"].plot.hist(bins=10, edgecolor=\"black\")\n",
    "plt.xlabel(\"Mean absolute error (k$)\")\n",
    "_ = plt.title(\"Test error distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La media del cross-validated testing error es: \"\n",
    "      f\"{cv_results['test_error'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26daca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La desviación estandar del testing error es: \"\n",
    "      f\"{cv_results['test_error'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c552fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracemos la distribución de la variable target\n",
    "\n",
    "target.plot.hist(edgecolor=\"black\")\n",
    "plt.xlabel(\"Median ArrDelay\")\n",
    "_ = plt.title(\"Target distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La desviación estándar del target es: {target.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a60589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el caso de que solo esté interesado en el score de la prueba,\n",
    "# scikit-learn proporciona la función cross_val_score.\n",
    "# Es idéntico a llamar a la función cross_validate y seleccionar solo test_score.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(regressor, data, target)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbf63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
